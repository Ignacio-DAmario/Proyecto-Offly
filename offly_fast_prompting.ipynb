{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece86ad2",
   "metadata": {},
   "source": [
    "# Offly ‚Äì Fast Prompting POC\n",
    "\n",
    "Esta Jupyter Notebook presenta una prueba de concepto (POC) para el curso \n",
    "\"Inteligencia Artificial: Generaci√≥n de Prompts\".\n",
    "\n",
    "El objetivo es demostrar c√≥mo el uso de t√©cnicas de Fast Prompting permite generar \n",
    "mensajes de concentraci√≥n personalizados para j√≥venes de forma eficiente, coherente \n",
    "y viable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fec692",
   "metadata": {},
   "source": [
    "## Contexto del problema\n",
    "\n",
    "Los j√≥venes se enfrentan diariamente a m√∫ltiples distracciones digitales que afectan \n",
    "su capacidad de concentraci√≥n. Las notificaciones constantes, las redes sociales y \n",
    "otras plataformas compiten por la atenci√≥n del usuario, generando dispersi√≥n y \n",
    "frustraci√≥n.\n",
    "\n",
    "Offly surge como una propuesta que busca acompa√±ar a los j√≥venes desde un enfoque \n",
    "emp√°tico y educativo, ofreciendo mensajes breves que ayuden a retomar el foco sin \n",
    "juzgar ni imponer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7449f",
   "metadata": {},
   "source": [
    "## Fast Prompting\n",
    "\n",
    "Fast Prompting es una t√©cnica que busca optimizar la interacci√≥n con modelos de \n",
    "lenguaje mediante prompts claros, reutilizables y eficientes.\n",
    "\n",
    "En lugar de crear m√∫ltiples prompts para cada situaci√≥n posible, se dise√±a un √∫nico \n",
    "prompt base que incorpora variables. Esto permite reducir la cantidad de consultas, \n",
    "mantener coherencia en el tono y optimizar costos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf63bcf",
   "metadata": {},
   "source": [
    "## Prompt base de Offly\n",
    "\n",
    "A continuaci√≥n se presenta el prompt base utilizado en esta prueba de concepto. \n",
    "Este prompt define la identidad, el tono y las reglas que deben seguir los mensajes \n",
    "generados por Offly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bed857",
   "metadata": {},
   "source": [
    "Sos Offly, una aplicaci√≥n que ayuda a j√≥venes a mejorar su concentraci√≥n de manera \n",
    "amable y realista.\n",
    "\n",
    "Tu tono es emp√°tico, juvenil y esperanzador.\n",
    "Nunca juzg√°s, no ret√°s ni culpabiliz√°s al usuario.\n",
    "Normaliz√°s las distracciones como parte del proceso.\n",
    "\n",
    "Gener√°s un solo mensaje breve, de m√°ximo 20 palabras, que ayude al usuario a volver \n",
    "a enfocarse.\n",
    "\n",
    "Ten√© en cuenta la siguiente informaci√≥n del usuario:\n",
    "- Nivel de distracci√≥n\n",
    "- Estado emocional\n",
    "- Momento del d√≠a\n",
    "\n",
    "El mensaje debe ser claro, positivo y cercano.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bff7f",
   "metadata": {},
   "source": [
    "## Variables de entrada\n",
    "\n",
    "Para personalizar los mensajes sin necesidad de crear m√∫ltiples prompts, se utilizan \n",
    "las siguientes variables:\n",
    "\n",
    "- Nivel de distracci√≥n (bajo, medio, alto)\n",
    "- Estado emocional (neutral, cansado, frustrado, motivado)\n",
    "- Momento del d√≠a (ma√±ana, tarde, noche)\n",
    "\n",
    "Estas variables permiten adaptar el mensaje manteniendo una estructura √∫nica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec331d",
   "metadata": {},
   "source": [
    "## Ejemplos de uso del prompt base\n",
    "\n",
    "Ejemplo 1:\n",
    "- Nivel de distracci√≥n: alto\n",
    "- Estado emocional: frustrado\n",
    "- Momento del d√≠a: noche\n",
    "\n",
    "Ejemplo 2:\n",
    "- Nivel de distracci√≥n: medio\n",
    "- Estado emocional: cansado\n",
    "- Momento del d√≠a: tarde\n",
    "\n",
    "Ejemplo 3:\n",
    "- Nivel de distracci√≥n: bajo\n",
    "- Estado emocional: motivado\n",
    "- Momento del d√≠a: ma√±ana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e1543",
   "metadata": {},
   "source": [
    "## Optimizaci√≥n y eficiencia\n",
    "\n",
    "El uso de un √∫nico prompt base con variables permite reducir la cantidad de consultas \n",
    "necesarias al modelo de lenguaje. En lugar de generar un prompt distinto para cada \n",
    "escenario, se reutiliza una estructura com√∫n, lo que mejora la eficiencia, reduce \n",
    "costos y facilita el mantenimiento del sistema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3978cec",
   "metadata": {},
   "source": [
    "## Conclusi√≥n\n",
    "\n",
    "Esta prueba de concepto demuestra que, mediante t√©cnicas de Fast Prompting, es posible \n",
    "generar mensajes personalizados y coherentes utilizando una estructura simple y \n",
    "optimizada.\n",
    "\n",
    "Las t√©cnicas implementadas mejoran la propuesta presentada en la primera entrega, \n",
    "haciendo la soluci√≥n m√°s escalable, viable y alineada con un uso real de inteligencia \n",
    "artificial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effcf577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_prompt_offly(nivel_distraccion, estado_emocional, momento_del_dia):\n",
    "    \"\"\"\n",
    "    Genera el prompt base de Offly utilizando variables para personalizar el mensaje.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Sos Offly, una aplicaci√≥n que ayuda a j√≥venes a mejorar su concentraci√≥n de manera amable y realista.\n",
    "\n",
    "Tu tono es emp√°tico, juvenil y esperanzador.\n",
    "Nunca juzg√°s, no ret√°s ni culpabiliz√°s al usuario.\n",
    "Normaliz√°s las distracciones como parte del proceso.\n",
    "\n",
    "Gener√°s un solo mensaje breve, de m√°ximo 20 palabras, que ayude al usuario a volver a enfocarse.\n",
    "\n",
    "Ten√© en cuenta la siguiente informaci√≥n del usuario:\n",
    "- Nivel de distracci√≥n: {nivel_distraccion}\n",
    "- Estado emocional: {estado_emocional}\n",
    "- Momento del d√≠a: {momento_del_dia}\n",
    "\n",
    "El mensaje debe ser claro, positivo y cercano.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32edac44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sos Offly, una aplicaci√≥n que ayuda a j√≥venes a mejorar su concentraci√≥n de manera amable y realista.\n",
      "\n",
      "Tu tono es emp√°tico, juvenil y esperanzador.\n",
      "Nunca juzg√°s, no ret√°s ni culpabiliz√°s al usuario.\n",
      "Normaliz√°s las distracciones como parte del proceso.\n",
      "\n",
      "Gener√°s un solo mensaje breve, de m√°ximo 20 palabras, que ayude al usuario a volver a enfocarse.\n",
      "\n",
      "Ten√© en cuenta la siguiente informaci√≥n del usuario:\n",
      "- Nivel de distracci√≥n: alto\n",
      "- Estado emocional: frustrado\n",
      "- Momento del d√≠a: noche\n",
      "\n",
      "El mensaje debe ser claro, positivo y cercano.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_ejemplo = generar_prompt_offly(\n",
    "    nivel_distraccion=\"alto\",\n",
    "    estado_emocional=\"frustrado\",\n",
    "    momento_del_dia=\"noche\"\n",
    ")\n",
    "\n",
    "print(prompt_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67105ba",
   "metadata": {},
   "source": [
    "## Ejemplo de salida esperada del modelo\n",
    "\n",
    "A partir del prompt generado, el modelo de IA devolver√≠a un mensaje como:\n",
    "\n",
    "\"Es normal sentirse frustrado a esta hora. Empez√° con algo peque√±o, estamos avanzando üíõ\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25fb87",
   "metadata": {},
   "source": [
    "## An√°lisis de costos y consultas a la API\n",
    "\n",
    "Sin Fast Prompting:\n",
    "- 1 consulta para definir el rol\n",
    "- 1 consulta para el tono\n",
    "- 1 consulta para el contexto del usuario\n",
    "- 1 consulta para generar el mensaje final\n",
    "\n",
    "Total: 4 consultas por mensaje\n",
    "\n",
    "Con Fast Prompting:\n",
    "- 1 √∫nico prompt que incluye rol, tono, reglas y contexto\n",
    "\n",
    "Total: 1 consulta por mensaje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885018f",
   "metadata": {},
   "source": [
    "### Simulaci√≥n de costos\n",
    "\n",
    "Suponiendo una aplicaci√≥n con 1000 mensajes diarios:\n",
    "\n",
    "- Enfoque no optimizado: 4000 consultas diarias\n",
    "- Enfoque optimizado (Fast Prompting): 1000 consultas diarias\n",
    "\n",
    "Esto representa una reducci√≥n del 75% en el uso de la API, mejorando la viabilidad econ√≥mica\n",
    "y la escalabilidad del proyecto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b057fde",
   "metadata": {},
   "source": [
    "## An√°lisis de la implementaci√≥n\n",
    "\n",
    "La funci√≥n implementada permite reutilizar un √∫nico prompt base y personalizarlo \n",
    "mediante variables. Esta estrategia reduce la cantidad de consultas necesarias al \n",
    "modelo de lenguaje y mantiene coherencia en el tono de la aplicaci√≥n.\n",
    "\n",
    "El enfoque mejora la propuesta presentada en la primera entrega, ya que hace la \n",
    "soluci√≥n m√°s eficiente, escalable y viable desde el punto de vista t√©cnico y econ√≥mico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1c0a1",
   "metadata": {},
   "source": [
    "## Relaci√≥n con la Preentrega 1\n",
    "\n",
    "En la primera entrega se propuso el uso de inteligencia artificial para generar \n",
    "mensajes personalizados dentro de Offly. En esta segunda entrega, dicha propuesta \n",
    "se profundiza mediante la aplicaci√≥n de t√©cnicas de Fast Prompting, que permiten \n",
    "optimizar el uso del modelo, reducir consultas innecesarias y mejorar la viabilidad \n",
    "t√©cnica de la soluci√≥n.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
